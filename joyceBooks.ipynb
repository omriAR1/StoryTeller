{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9JQru33zUDX"
      },
      "source": [
        "# Downloads & Setup\n",
        "Nltk is a suite of libraries stical natural language processing for English written in Python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rA2PNEMv33h"
      },
      "source": [
        "### Books\n",
        "James Joyce books downloaded from the [Gutenberg Project](https://www.gutenberg.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgi-VcHGq6-k"
      },
      "source": [
        "### punkt\n",
        "This tokenizer divides a text into a list of sentences\n",
        "by using an unsupervised algorithm to build a model for abbreviation\n",
        "words, collocations, and words that start sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr-YcSTHrGdB"
      },
      "source": [
        "### stopwords\n",
        "some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called stop words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7VnBaoTru6a"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dNR8598sPrC",
        "outputId": "5a3a017e-da67-43d8-ecfe-c8239e07cce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jgsM3bKOdmMG"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import time\n",
        "\n",
        "import pandas\n",
        "import numpy\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "\n",
        "from random import randint\n",
        "from collections import Counter\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G3XdiUgr0PU"
      },
      "source": [
        "# Data\n",
        "For this project we access the writing of [james joyce](https://en.wikipedia.org/wiki/James_Joyce) that is famous for his experimental use of language and exploration of new literary methods, including interior monologue, use of a complex network of symbolic parallels, and invented words, puns, and allusions in his novels.\n",
        "We will consume the following writings:\n",
        "\n",
        "ChamberMusic, Dubliners, Exiles, Portait of the Artist, Ulysses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-JUKqIdx8xc"
      },
      "source": [
        "## Data Cleaning Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJz-F6aIs18C"
      },
      "source": [
        "### Html\n",
        "removes taggs or patterns cotaining links."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YvYYecfUx_-h"
      },
      "outputs": [],
      "source": [
        "def html_pattern():\n",
        "    return re.compile('<.*?>')\n",
        "\n",
        "\n",
        "def remove_html(text):\n",
        "  \"\"\"\n",
        "  REMOVE HTML CODES\n",
        "  \"\"\"\n",
        "  return html_pattern().sub(r'', text)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BnMma8iyRey"
      },
      "source": [
        "### Non-Ascii characters\n",
        "Remove any traces of illegal characters in the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9_hxu3-SyVBx"
      },
      "outputs": [],
      "source": [
        "def remove_non_ascii(row):\n",
        "    \"\"\"\n",
        "    REMOVE NON ASCII CHARACTERS\n",
        "    \"\"\"\n",
        "    cleaned = \"\"\n",
        "    for word in row[\"text\"]:\n",
        "        if word.isascii():\n",
        "            cleaned += word\n",
        "    return cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CWnd73WteQA"
      },
      "source": [
        "### Words length filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahVozx0VyjnJ"
      },
      "source": [
        "We remove any words that is 1 character in length, in addition to empty lines and multiple spaces \"words\".\n",
        "As one of the books is a poem collection - it is very common to have multiple empty lines in a row, reporesting a page turn.\n",
        "Multiple spaces in a row represnts the poem style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7ezEVFI2yn_N"
      },
      "outputs": [],
      "source": [
        "def remove_single_char_func(text, threshold=1):\n",
        "    '''\n",
        "    Removes single characters from string, if present\n",
        "    \n",
        "    Step 1: Use word_tokenize() to get tokens from string\n",
        "    Step 2: Removes words whose length falls below the threshold (by default = 1)\n",
        "    \n",
        "    Args:\n",
        "        text (str): String to which the functions are to be applied, string\n",
        "    \n",
        "    Returns:\n",
        "        String with removed words whose length was below the threshold (by default = 1)\n",
        "    ''' \n",
        "    threshold = threshold\n",
        "    \n",
        "    words = word_tokenize(text)\n",
        "    text = ' '.join([word for word in words if len(word) > threshold])\n",
        "    return text\n",
        "\n",
        "def remove_multiple_spaces(text):\n",
        "  spaces_pattern= re.compile('\\s{2,}')\n",
        "  return spaces_pattern.sub(' ', text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pRU9fsIyswD"
      },
      "source": [
        "### Lower Casing\n",
        "To reduce the amount of data in the model, subbing all upper case letters to the lower case form.\n",
        "The main feature is the amount of unique words, in the spoken language there is no different between \"Hello\" and \"hello\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "05m5Yx4vyt81"
      },
      "outputs": [],
      "source": [
        "def make_lower_case(text):\n",
        "    \"\"\"\n",
        "    MAKE DESCRIPTION TEXT LOWER CASE\n",
        "    \"\"\"\n",
        "    cleaned = \"\"\n",
        "    for word in text[\"cleaned_description\"]:\n",
        "        cleaned += word.lower()\n",
        "    return cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF8ay3RTy7KP"
      },
      "source": [
        "### stop words and panctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TkA2MHhSy9si"
      },
      "outputs": [],
      "source": [
        "def remove_punctuations(text):\n",
        "    text = re.sub(r\"[^a-zA-Z]\", ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_stop_words(text):\n",
        "    \"\"\"\n",
        "    REMOVE STOP WORDS\n",
        "    \"\"\"\n",
        "    text = text.split()\n",
        "    stops = set(stopwords.words('english'))\n",
        "    text = [word for word in text if word not in stops]\n",
        "    text = \" \".join(text)\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjnI8OJLvgBI"
      },
      "source": [
        "## Organising Data\n",
        "This model use pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) to drive the pre-processing of text.\n",
        "Datafarme methods are implemented in c++, providing high performance and convient way to process data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "26upDpk1e6J3"
      },
      "outputs": [],
      "source": [
        "def clean_book(book_file):\n",
        "    raw_text_file = book_file.read()\n",
        "    return remove_html(raw_text_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QurON6utp385"
      },
      "outputs": [],
      "source": [
        "def create_book_df():\n",
        "  book_list = [fold for file, der, fold in os.walk(\"book_project/\")][0]\n",
        "  books_df = pandas.DataFrame(columns=[\"book_name\", \"text\"])\n",
        "  for book in book_list:\n",
        "      with open(f\"book_project/{book}\", encoding=\"utf-8\") as book_file:\n",
        "          cleaned = clean_book(book_file)\n",
        "          books_df = books_df.append({\"book_name\": book, \"text\": cleaned}, ignore_index=True)\n",
        "  books_df[\"cleaned_description\"] = books_df.apply(lambda book_row: remove_non_ascii(book_row), axis=1)\n",
        "  books_df[\"cleaned_description\"] = books_df.apply(lambda book_row: make_lower_case(book_row), axis=1)\n",
        "  books_df[\"cleaned_description\"] = books_df.cleaned_description.apply(remove_stop_words)\n",
        "  books_df[\"cleaned_description\"] = books_df.cleaned_description.apply(remove_punctuations)\n",
        "  books_df[\"cleaned_description\"] = books_df.cleaned_description.apply(remove_single_char_func)\n",
        "  books_df[\"cleaned_description\"] = books_df.cleaned_description.apply(remove_multiple_spaces)\n",
        "  return books_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bbiVU4FwQH5"
      },
      "source": [
        "## Tokenizing Words\n",
        "First lets examine our data.\n",
        "We should have all the letters in the english language in addition to the space letter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JiszSvNWqRdX"
      },
      "outputs": [],
      "source": [
        "books_df = create_book_df()\n",
        "\n",
        "all_words = \"\"\n",
        "for index, row in books_df.iterrows():\n",
        "    all_words += row[\"cleaned_description\"]\n",
        "\n",
        "vocab = sorted(set(all_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiG_FoUVRbXI"
      },
      "outputs": [],
      "source": [
        "print(f\"{len(vocab)} unique characters\")\n",
        "all_words_set = Counter(all_words.split())\n",
        "print(f\"Unique words: {len(all_words_set)}\")\n",
        "print(f\"Most frequnetly used words: {all_words_set.most_common(10)}\")\n",
        "top_ten_words = 0\n",
        "for word in all_words_set.most_common(10):\n",
        "  top_ten_words+= word[1]\n",
        "\n",
        "top_twenty_words = 0\n",
        "for word in all_words_set.most_common(20):\n",
        "  top_twenty_words+= word[1]\n",
        "print(f\"Top 10 words are {top_ten_words/len(all_words_set)*100}% of all words\")\n",
        "print(f\"Top 20 words are {top_twenty_words/len(all_words_set)*100}% of all words\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rBWc6Zfy3xO"
      },
      "source": [
        "## Token mapping\n",
        "Our model is character based, and as such, we provide two sets of mappings -\n",
        "charcter to id\n",
        "id to charcter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yWUfdERCBOKu"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4Drh5oxH_oXy"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "S81-gVBwrjwJ"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7mxsBq8I-wGx"
      },
      "outputs": [],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(all_words, 'UTF-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XOzRSCYE-qZ6"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TINc_obq-sUw"
      },
      "outputs": [],
      "source": [
        "seq_length = 100\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdJtY3g-zpY_"
      },
      "source": [
        "## Split text sequnces\n",
        "Training requires a dataset of `(input, label)` pairs. Where `input` and \n",
        "`label` are sequences. At each time step the input is the current character and the label is the next character.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PlmPSeD9sL7z"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xGVdttvksSyA"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDObYFNX0HKi"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCaolp1h0NOa"
      },
      "source": [
        "## Settings\n",
        "Settings for the nn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_kxTKeJEHQL"
      },
      "source": [
        "### Features size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "YPoW087jELT7"
      },
      "outputs": [],
      "source": [
        "dimension_factor = 8\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 2**dimension_factor\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 2**(dimension_factor+2)\n",
        "\n",
        "# Batch size\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 10000\n",
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzeYrTBQshwb",
        "outputId": "a83aebbc-ee0f-48d4-bfb4-07bef519a26e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(128, 100), dtype=tf.int64, name=None), TensorSpec(shape=(128, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njhWeGngEtOe"
      },
      "source": [
        "## Model Architecture \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5VR4ph65Wzm"
      },
      "source": [
        "### Defining loss algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ftBbaTIY5a9f"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def plot_model_loss(model_history):\n",
        "  plt.plot(model_history.history['loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['loss'], loc='upper right')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "4VbMzILB8FIF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utxYmQSY5iFO"
      },
      "source": [
        "### Defining optimizer algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "OkQLFATr5uHG"
      },
      "outputs": [],
      "source": [
        "optimizer ='adam'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C97-5lk3YfR"
      },
      "source": [
        "### GRU Based Model\n",
        "keras.layers.Embedding -> keras.layers.GRU -> keras.layers.Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBM-BuaXs3tA",
        "outputId": "ca5aa170-d68e-408e-84d8-66cfce9b7e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 83) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x\n",
        "\n",
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "\n",
        "# initiate model so we can check its summary\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOWbgI3zHQ_8"
      },
      "source": [
        "### Experiment with added layers\n",
        "Lets add another RNN layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0jPj99VBXni",
        "outputId": "45eb0574-55d3-4379-99b7-fe3cff89b8db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 100, 28) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "class MyModelExpirement(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.simple = tf.keras.layers.SimpleRNN(rnn_units, return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x, states = self.simple(x, states)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x\n",
        "\n",
        "model = MyModelExpirement(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "\n",
        "# initiate model so we can check its summary\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W2bdAls5Xz-",
        "outputId": "092e32fc-33bf-4a2c-e099-205cca3ac862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_expirement_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     multiple                  7168      \n",
            "                                                                 \n",
            " gru_2 (GRU)                 multiple                  3938304   \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    multiple                  2098176   \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  28700     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,072,348\n",
            "Trainable params: 6,072,348\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkjjZyr-LI0W"
      },
      "source": [
        "### Output before training\n",
        "Let see what we get from uuntrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mML1dn89CzkQ",
        "outputId": "45b39615-4f09-4421-a597-5674d327c2bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b' taps brow must kill priest king biddy clap hear professor said hes professor college cunty kate did'\n",
            "Next Char Predictions:\n",
            " b'ddmftdtf hmhrqaqvqmdhhdjpgeradxhectt[UNK]bxxigerzahj[UNK]zjw[UNK]takcgcbgy vsiizozhahgui ixxylgejedvuntjcmomtkdj'\n"
          ]
        }
      ],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtc2Dd1st8yd",
        "outputId": "6ee2c0ab-3da4-47d1-9176-faff3693582d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 100, 28) # (batch_size, sequence_length, vocab_size)\n",
            "Prediction shape:  (128, 100, 28)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(3.3323407, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "  \n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "31wu52jYDclP"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizer, loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sIMjZ8DFuFK"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "FW1iPd2HDXCe",
        "outputId": "9395d7fc-595f-4509-8cca-d9de945dd6a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-25cc55b1344d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 40, 82), found shape=(128, 100)\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xgkr95J0KPl"
      },
      "source": [
        "## Examining loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "qM1sa91az3PT",
        "outputId": "37969d8a-3349-4427-be25-98b1d6c0642e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z3/8dcnGyE7SyBkYRVkXxNFrWC1WsWtrmBdRn+t1tZaHf1Z2zr92ZnpTDtdtB21tUy11Q5lUbFita6tIq0CIewEEUEgCxBAErZAls/vj3sJAQMEyM1Jct/PxyMPwj3fm/vOVfLOOd9zvsfcHRERiV4xQQcQEZFgqQhERKKcikBEJMqpCEREopyKQEQkyqkIRESinIpApJnM7Pdm9sNmjv3EzL5wql9HpDWoCEREopyKQEQkyqkIpEMJH5J5wMyWmdkeM3vKzHqa2V/MbJeZvWVmXRqNv8LMVprZTjN7x8yGNNo2xsyKws+bCSQe8VqXmdmS8HP/YWYjTzLz7Wa21sx2mNkcM8sOP25m9qiZbTWzKjNbbmbDw9smmdmqcLZSM/u/J/WGiaAikI7pGuBCYBBwOfAX4HtAJqH/578FYGaDgOnAveFtrwIvm1mCmSUAfwL+AHQFngt/XcLPHQM8DXwN6Ab8BphjZp1OJKiZnQ/8CLge6AVsAGaEN18ETAh/H+nhMdvD254CvubuqcBw4K8n8roijakIpCN6zN23uHsp8B4w390Xu3s18CIwJjxuMvCKu7/p7jXAz4DOwNnAeCAe+IW717j788DCRq9xB/Abd5/v7nXu/gywP/y8E3Ej8LS7F7n7fuC7wFlm1heoAVKBwYC5e7G7l4efVwMMNbM0d//U3YtO8HVFGqgIpCPa0ujzfU38PSX8eTah38ABcPd6YBOQE95W6oevyrih0ed9gPvDh4V2mtlOIC/8vBNxZIbdhH7rz3H3vwKPA08AW81sqpmlhYdeA0wCNpjZu2Z21gm+rkgDFYFEszJCP9CB0DF5Qj/MS4FyICf82EG9G32+CfgPd89o9JHk7tNPMUMyoUNNpQDu/t/uPg4YSugQ0QPhxxe6+5VAD0KHsGad4OuKNFARSDSbBVxqZheYWTxwP6HDO/8A3gdqgW+ZWbyZXQ2c0ei5/wPcaWZnhid1k83sUjNLPcEM04HbzGx0eH7hPwkdyvrEzArCXz8e2ANUA/XhOYwbzSw9fEirCqg/hfdBopyKQKKWu38I3AQ8BmwjNLF8ubsfcPcDwNXArcAOQvMJsxs9txC4ndChm0+BteGxJ5rhLeD7wAuE9kIGAFPCm9MIFc6nhA4fbQd+Gt52M/CJmVUBdxKaaxA5KaYb04iIRDftEYiIRDkVgYhIlFMRiIhEORWBiEiUiws6wInq3r279+3bN+gYIiLtyqJFi7a5e2ZT29pdEfTt25fCwsKgY4iItCtmtuFo23RoSEQkyqkIRESinIpARCTKtbs5AhGRllBTU0NJSQnV1dVBR2lRiYmJ5ObmEh8f3+znqAhEJCqVlJSQmppK3759OXyR2fbL3dm+fTslJSX069ev2c/ToSERiUrV1dV069atw5QAgJnRrVu3E97LURGISNTqSCVw0Ml8T1FTBGu37ubfXl7FgVot2y4i0ljUFMGmHXt5+u/r+evqLccfLCLSClJSUo4/qBVETRFMGJRJVloiMxZuCjqKiEibEjVFEBtjXJ+fy7trKijduS/oOCIiDdydBx54gOHDhzNixAhmzpwJQHl5ORMmTGD06NEMHz6c9957j7q6Om699daGsY8++ugpv35UnT56XX4ej/1tLc8VbuLeLwwKOo6ItBH/+vJKVpVVtejXHJqdxsOXD2vW2NmzZ7NkyRKWLl3Ktm3bKCgoYMKECfzxj3/ki1/8Ig899BB1dXXs3buXJUuWUFpayooVKwDYuXPnKWeNmj0CgLyuSXzutO48V1hCXb1u0SkibcO8efO44YYbiI2NpWfPnkycOJGFCxdSUFDA7373O37wgx+wfPlyUlNT6d+/P+vWrePuu+/mtddeIy0t7ZRfP6r2CACmFPTmrj8WMW/tNiYOanJFVhGJMs39zb21TZgwgblz5/LKK69w6623ct9993HLLbewdOlSXn/9dZ588klmzZrF008/fUqvE1V7BABfGNqDrskJzFy4MegoIiIAnHvuucycOZO6ujoqKiqYO3cuZ5xxBhs2bKBnz57cfvvtfPWrX6WoqIht27ZRX1/PNddcww9/+EOKiopO+fWjbo+gU1wsV4/J4Zn3P2Hb7v10T+kUdCQRiXJXXXUV77//PqNGjcLM+MlPfkJWVhbPPPMMP/3pT4mPjyclJYVnn32W0tJSbrvtNurrQ9dE/ehHPzrl1zf39nWsPD8/30/1xjQfbdnFhY/O5aFJQ7h9Qv8WSiYi7UlxcTFDhgwJOkZENPW9mdkid89vanzEDg2ZWZ6Z/c3MVpnZSjO75xhjC8ys1syujVSexgb2TGVcny7MWLiR9laEIiItLZJzBLXA/e4+FBgP3GVmQ48cZGaxwH8Bb0Qwy2dMLsjj44o9FG74tDVfVkSkzYlYEbh7ubsXhT/fBRQDOU0MvRt4AdgaqSxNuXREL1I6xTFjga40FolWHfGIwMl8T61y1pCZ9QXGAPOPeDwHuAr49XGef4eZFZpZYUVFRYtkSu4Ux+WjsnlleRlV1TUt8jVFpP1ITExk+/btHaoMDt6PIDEx8YSeF/GzhswshdBv/Pe6+5GX7v0CeNDd64+1dKq7TwWmQmiyuKWy3XBGHtMXbGTOkjJuGt+npb6siLQDubm5lJSU0FK/XLYVB+9QdiIiWgRmFk+oBKa5++wmhuQDM8Il0B2YZGa17v6nSOY6aEROOkN6pTFz4SYVgUiUiY+PP6G7eHVkkTxryICngGJ3f6SpMe7ez937untf4HngG61VAuGMTCnIY3lpJStKK1vrZUVE2pRIzhGcA9wMnG9mS8Ifk8zsTjO7M4Kve0K+NDqHhLgYZhVq0lhEolPEDg25+zyg2fdMc/dbI5XlWNKT4pk0PIsXF5fyvUlDSIyPDSKGiEhgom6toaZMLujNrupaXl1eHnQUEZFWpyIAxvfvSt9uSbp7mYhEJRUBoUnjyQW9WbB+B+sqdgcdR0SkVakIwq4Zl0NsjDFTk8YiEmVUBGE9UhO5YHAPXlhUQk1dfdBxRERajYqgkSln5LFt9wHeLm7VZY9ERAKlImhkwsBMstISdfcyEYkqKoJG4mJjuC4/l3fXVFC2c1/QcUREWoWK4AjX5+dR7/BcYUnQUUREWoWK4Ah5XZP43GndmVW4ibr6jrM8rYjI0agImjDljDxKd+7j72u3BR1FRCTiVARNuHBoT7okxTNTVxqLSBRQETShU1wsV4/N5Y1Vm9m+e3/QcUREIkpFcBSTC/KoqXNeXFwadBQRkYhSERzFoJ6pjO2dwYyFmzrUPU1FRI6kIjiGKQW9Wbt1N0UbPw06iohIxKgIjuHSkb1ITohl+gJNGotIx6UiOIbkTnFcMTqHV5aVU1VdE3QcEZGIUBEcx5SCPPbV1PHy0rKgo4iIRISK4DhG5qYzOCtV1xSISIelIjgOM2NKQR7LSipZWVYZdBwRkRanImiGL43JISEuhlnaKxCRDkhF0AwZSQlcMjyLFxeXUl1TF3QcEZEWpSJopskFeVRV1/Lais1BRxERaVEqgmYa368bfbolMX2B7l4mIh1LxIrAzPLM7G9mtsrMVprZPU2MudHMlpnZcjP7h5mNilSeUxUTY0wuyGP++h2sq9gddBwRkRYTyT2CWuB+dx8KjAfuMrOhR4xZD0x09xHAvwNTI5jnlF07NpfYGGOW7l4mIh1IxIrA3cvdvSj8+S6gGMg5Ysw/3P3gQj4fALmRytMSeqQlcv7gHjy/qISauvqg44iItIhWmSMws77AGGD+MYZ9BfjLUZ5/h5kVmllhRUVFywc8AVMK8ti2ez9/Xb010BwiIi0l4kVgZinAC8C97l51lDGfJ1QEDza13d2nunu+u+dnZmZGLmwzTByUSc+0TrrSWEQ6jIgWgZnFEyqBae4++yhjRgK/Ba509+2RzNMS4mJjuG5cHu98uJXyyn1BxxEROWWRPGvIgKeAYnd/5ChjegOzgZvdfU2ksrS06/PzqHd4XpPGItIBRHKP4BzgZuB8M1sS/phkZnea2Z3hMf8P6Ab8Kry9MIJ5Wkzvbkl87rTuzCzcRH297l4mIu1bXKS+sLvPA+w4Y74KfDVSGSJpckEed09fzN8/3sa5A4OdtxARORW6svgkXTSsJxlJ8czQpLGItHMqgpPUKS6Wq8fk8sbKzezYcyDoOCIiJ01FcAomF+RRU+fMLtKksYi0XyqCU3B6Vipjemcwc+Em3DVpLCLtk4rgFE0pyOOjrbsp2rgz6CgiIidFRXCKLhuZTXJCLDMXanlqEWmfVASnKLlTHFeMzublpeXsqq4JOo6IyAlTEbSAyQW92VdTx8tLy4OOIiJywlQELWBUbjqDs1J1eEhE2iUVQQswC929bGlJJavKmlxgVUSkzVIRtJCrxuSQEBfDrEJdaSwi7YuKoIVkJCVw8bAsZheVUF1TF3QcEZFmUxG0oCkFeVRV1/L6ys1BRxERaTYVQQsa378bfbolMWOBDg+JSPuhImhBMTHG9fl5vL9uO59s2xN0HBGRZlERtLBrx+USG2PM1KSxiLQTKoIW1jMtkc+f3oPnF5VQU1cfdBwRkeNSEUTAlII8Knbt52+rtwYdRUTkuFQEEXDe6Zn0SO3ETN29TETaARVBBMTFxnBdfi5/+3Armyurg44jInJMKoIIuT4/j3qH5xdpr0BE2jYVQYT06ZbMOad1Y2bhJurrdfcyEWm7VAQRNLmgN5t27OMfH28POoqIyFGpCCLooqE9yUiKZ4aWpxaRNkxFEEGJ8bFcNSaHN1ZuYceeA0HHERFpUsSKwMzyzOxvZrbKzFaa2T1NjDEz+28zW2tmy8xsbKTyBGVyQR4H6up5cXFp0FFERJoUyT2CWuB+dx8KjAfuMrOhR4y5BBgY/rgD+HUE8wRicFYao/MymLlwI+6aNBaRtidiReDu5e5eFP58F1AM5Bwx7ErgWQ/5AMgws16RyhSUKQV5rNmym8WbdgYdRUTkM1pljsDM+gJjgPlHbMoBGp9oX8JnywIzu8PMCs2ssKKiIlIxI+byUdkkJ8QyU8tTi0gbFPEiMLMU4AXgXnc/qRv6uvtUd8939/zMzMyWDdgKkjvFcfmobF5eVsbu/bVBxxEROUxEi8DM4gmVwDR3n93EkFIgr9Hfc8OPdTiTC/LYe6COPy8tCzqKiMhhInnWkAFPAcXu/shRhs0BbgmfPTQeqHT38khlCtLovAxO75nKdC1EJyJtTCT3CM4BbgbON7Ml4Y9JZnanmd0ZHvMqsA5YC/wP8I0I5gmUmTG5II+lm3ZSXH5SR8hERCIiLlJf2N3nAXacMQ7cFakMbc1VY3L48V9WM3PhJn5wxbCg44iIALqyuFV1SU7gi8OzeKGoRMtTi0iboSJoZfd+YSD19c43/1ikW1mKSJugImhlAzJT+NE1Iync8Ck/eW110HFERFQEQbhiVDa3nNWH/3lvPa+t2Bx0HBGJciqCgDx06RBG5abzwHNL2bB9T9BxRCSKqQgC0ikulse/PJaYGOMb04qorqkLOpKIRCkVQYDyuibx6ORRrCyr4l9fXhV0HBGJUs0qAjO7x8zSwlcAP2VmRWZ2UaTDRYPzB/fk6+cNYPqCjcwuKgk6johEoebuEfyf8IJxFwFdCF0x/OOIpYoy9184iDP7deWhF1fw4eZdQccRkSjT3CI4eIXwJOAP7r6S41w1LM0XFxvDYzeMIblTHF+ftkgrlIpIq2puESwyszcIFcHrZpYK6GqoFtQjLZHHbhjDJ9v28N3Zy3U3MxFpNc0tgq8A3wEK3H0vEA/cFrFUUeqsAd24/6LTeXlpGX/4YEPQcUQkSjS3CM4CPnT3nWZ2E/AvQGXkYkWvr08cwPmDe/Dvf17FEt3aUkRaQXOL4NfAXjMbBdwPfAw8G7FUUSwmxnjk+lH0SE3krmlF7Nx7IOhIItLBNbcIasNLRl8JPO7uTwCpkYsV3TKSEnjixrFs3VXNfbOWUl+v+QIRiZzmFsEuM/suodNGXzGzGELzBBIho/My+P5lQ/nr6q08OffjoOOISAfW3CKYDOwndD3BZkL3Fv5pxFIJADeP78Plo7L52esf8v7H24OOIyIdVLOKIPzDfxqQbmaXAdXurjmCCDMzfnT1CPp2T+bu6YvZWqWb2YhIy2vuEhPXAwuA64Drgflmdm0kg0lISqc4fn3jOHbvr+Hu6Yup1c1sRKSFNffQ0EOEriH4J3e/BTgD+H7kYkljp2el8p9XjWD++h088uaaoOOISAfT3CKIcfetjf6+/QSeKy3g6rG53HBGHr9652PeLt4SdBwR6UCa+8P8NTN73cxuNbNbgVeAVyMXS5ry8OXDGNorjftmLWXTjr1BxxGRDqK5k8UPAFOBkeGPqe7+YCSDyWclxsfy65vGUu/OXX8sYn+tbmYjIqeu2Yd33P0Fd78v/PFiJEPJ0fXplsxPrx3FspJK/uOV4qDjiEgHcMwiMLNdZlbVxMcuM6tqrZByuIuHZ3H7uf149v0NzFlaFnQcEWnn4o610d21jEQb9e2LB7N4406+88IyhvZK47QeKUFHEpF2KmJn/pjZ02a21cxWHGV7upm9bGZLzWylmWlZ6xMQHxvD418eS+f4WL4xbRF7D+hmNiJyciJ5CujvgYuPsf0uYJW7jwLOA35uZgkRzNPhZKUn8sspY/ho627+5cUVupmNiJyUiBWBu88FdhxrCJBqZgakhMfq19oT9LmB3bn3gkHMXlzKjIWbgo4jIu1QkBeFPQ4MAcqA5cA97t7k+glmdoeZFZpZYUVFRWtmbBfuPv80zh3YnYfnrGRFqe4XJCInJsgi+CKwBMgGRgOPm1laUwPdfaq757t7fmZmZmtmbBdiYoxfTB5N16QEvjGtiMp9NUFHEpF2JMgiuA2Y7SFrgfXA4ADztGvdUjrxxI1jKNu5jweeW6r5AhFptiCLYCNwAYCZ9QROB9YFmKfdG9enK9+5ZDBvrNrCb99bH3QcEWknjnkdwakws+mEzgbqbmYlwMOE72rm7k8C/w783syWAwY86O7bIpUnWnzlc/0o/ORTfvzaakb3zqCgb9egI4lIG2ft7RBCfn6+FxYWBh2jTauqruGKx+axr6aOV751Lt1TOgUdSUQCZmaL3D2/qW1aSroDSkuM54kbx7Jzbw33zlhCXX37KnsRaV0qgg5qWHY6/3blMOat3cYv3/4o6Dgi0oapCDqw6/PzuGZsLo/99SPeXaPrL0SkaSqCDszM+OGXhnN6z1TunbGYsp37go4kIm2QiqCD65wQyxM3juVAbT3f/GMRNXVNXrwtIlFMRRAFBmSm8F/XjqRo405+/JfVQccRkTZGRRAlLhuZza1n9+Wpeev5y/LyoOOISBuiIogi35s0hNF5GXz7+WWs37Yn6Dgi0kaoCKJIQlwMT9w4lthY4+v/u4jqmrqgI4lIG6AiiDI5GZ15dPJoVm/exb0zlrBz74GgI4lIwFQEUejzp/fgoUlDeLN4Cxf8/F1mF5VotVKRKKYiiFK3T+jPy9/8HHldk7hv1lJu/O18Pq7YHXQsEQmAiiCKDc1OY/bXz+aHXxrO8tJKLvnFezzy5hrNHYhEGRVBlIuJMW4a34e375/IJSOy+O+3P+KSX77HvI+0IrhItFARCAA9UhP55ZQx/OErZ+Du3PTUfO6dsZiKXfuDjiYiEaYikMOcOzCT1+6dwLcuGMiryzdzwc/fYdr8DdRrKWuRDktFIJ+RGB/LfRcO4tV7zmVodhoPvbiCa578B8XlVUFHE5EIUBHIUZ3WI4Xpt4/n59eNYsP2vVz22Dz+89Vi9h6oDTqaiLQgFYEck5lxzbhc3r5vIteNy2Xq3HVc+Mhc3lq1JehoItJCVATSLF2SE/jxNSN57s6zSO4Uy1efLeRrfyjUPQ5EOgAVgZyQgr5d+fPd5/LgxYN5d00FFz7yLr99bx21us+BSLulIpATlhAXw9fPG8Cb/zyRM/p15YevFHPF439nyaadQUcTkZOgIpCTltc1iadvLeBXN45l+579XPWrv/P9P62gqrom6GgicgJUBHJKzIxJI3rx1n0T+aez+jJt/gYu+Pm7zFlapoXsRNoJFYG0iNTEeH5wxTD+dNc5ZKUl8q3pi7nl6QVs2K4b4Ii0dRErAjN72sy2mtmKY4w5z8yWmNlKM3s3Ulmk9YzMzeBPd53Dw5cPZfHGnVz06Fwee/sj9tdqITuRtiqSewS/By4+2kYzywB+BVzh7sOA6yKYRVpRbIxx2zn9eOu+iVwwpAc/f3MNk375Hh+s2x50NBFpQsSKwN3nAjuOMeTLwGx33xgevzVSWSQYWemJ/OrGcfzu1gL219YzZeoH3D9rKTv26K5oIm1JkHMEg4AuZvaOmS0ys1uONtDM7jCzQjMrrKioaMWI0hI+P7gHb/7zRL5+3gBeWlLK+T9/h1kLN2khO5E2IsgiiAPGAZcCXwS+b2aDmhro7lPdPd/d8zMzM1szo7SQzgmxPHjxYF751rmclpnCt19YxpSpH7Bmy66go4lEvSCLoAR43d33uPs2YC4wKsA80gpOz0pl1tfO4sdXj+DDLbuY9Mv3ePD5Zbz/8XbqtIcgEoi4AF/7JeBxM4sDEoAzgUcDzCOtJCbGmHJGby4c2pOfvfEhLy0pY2bhJnqmdeLykdlcOTqH4TlpmFnQUUWigkXqoh8zmw6cB3QHtgAPA/EA7v5keMwDwG1APfBbd//F8b5ufn6+FxYWRiSzBGPvgVreLt7KS0vKeHfNVmrqnP7dk7l8VDZXjs6mf2ZK0BFF2j0zW+Tu+U1ua29Xf6oIOradew/wlxWbmbOkjA/Wb8cdRuSkc+XobC4bmU1WemLQEUXaJRWBtEubK6v587IyXlpSxvLSSszgzH5duXJ0DpcMzyIjKSHoiCLthopA2r11FbuZszRUCuu37SE+1pg4qAdXjs7mC0N60jkhNuiIIm2aikA6DHdnRWkVLy0p5eVlZWyp2k9SQiwXDe3JlaNz+NzA7sTHagktkSOpCKRDqqt3FqzfwZylpbyyrJyq6lq6JMVz6cheXDEqh/w+XYiJ0ZlHIqAikCiwv7aOuWu28dKSUt4q3kJ1TT3Z6YlcPjqbK0flMKRXqk5HlaimIpCosmd/LW+u2sJLS0qZ+9E26uqdgT1SuHJ0NleMyqF3t6SgI4q0OhWBRK3tu/fz6orNzFlSysJPPgVgdF4GV47O5tKRveiRqtNRJTqoCESA0p37eDl85lFxeRUxBuec1p3LR2Vz8fAs0hLjg44oEjEqApEjrNmyizlLypiztIyNO/aSEBdDfp8ujO/fjfH9uzEqL51OcTolVToOFYHIUbg7Szbt5M/LyvnHx9spLq8CoFNcDOPCxXBmv66M7p2hYpB27VhFEOSicyKBMzPG9O7CmN5dAPh0zwEWfLKD+et28MG67Tz61hrcQ8UwtvfBPYaujMrLIDFexSAdg/YIRI5h594DLFi/gw/W7WD++u2sKq/CHRLiYhjbO6PhUNJoFYO0cTo0JNJCKvfWsOCT0N7CB+sOL4YxeYeKYUxvFYO0LSoCkQip3FvDwoPFsH47K8s+Wwxn9u/K2N5dVAwSKBWBSCup3FfDwvWhw0gfrNvByrJK6h0SYmMY3XAoScUgrU9FIBKQyn01FIb3GOav38GK0kbFkJfB+P5dGd+/G2P7qBgkslQEIm1EVfXBYgiVQ+NiGJWXzpn9QhPPI3PT6ZGmq56l5ej0UZE2Ii0xnvMH9+T8wT2BUDEs+uTThsnnX72zlvrw72Y9UjsxMjedETmhYhiek05maqcA00tHpSIQCVBaYjyfH9yDzw/uAYTu37yqrIplJZUsL61kWclO3l69lYM77r3SExmRk95QDCNy0umWonKQU6MiEGlDkhLiyO/blfy+XRse272/lpWlB4uhkhWllbyxakvD9pyMzozISWdEbnp4DyJdt/GUE6IiEGnjUjrFcWb/bpzZv1vDY1XVNawoDZXCwb2H11Zubtie17UzI3MyGBEuhuE56aR31qJ60jQVgUg7lJYYz9kDunP2gO4Nj1XurWFF2cFi2Mmy0p28sry8YXvfbkmMyM1gRE4aI3IyGJ6TRqpWXBVUBCIdRnpSPOec1p1zTjtUDp/uOcDy8GGl5SWVFG34lJeXljVs75+ZHDqslJPOyNwMhmWnkdxJPxaijf6Li3RgXZITmDAokwmDMhse2757f0MxLCutZP66Hby0JFQOZjAgM4UROekMy05jaHYaw3qlk56kPYeOTNcRiAhbd1U3zDcc/HPrrv0N23MyOjMsO41h2YcKold6ou4D3Y4Ech2BmT0NXAZsdffhxxhXALwPTHH35yOVR0SOrkdqIucPTmy4vgGgYtd+VpVXsaqsipVllawqq+LN4i0Np7J2SYpnWHZ6aK8h/NGvewqxMSqH9iaSh4Z+DzwOPHu0AWYWC/wX8EYEc4jISchM7cTE1EwmNjqstGd/Las3V7GyrIqVpVWsKq/i93//hAN19QAkxscwOCutYe9haHYag7NStXxGGxexInD3uWbW9zjD7gZeAAoilUNEWk5ypzjG9enKuD6HrnOoqatn7dbd4T2H0N7DnKVlTJu/EYDYGGNAZnKoGHqlNRxa0rUObUdgk8VmlgNcBXye4xSBmd0B3AHQu3fvyIcTkWaLj41hSK80hvRK45pxocfcnZJP97GyrJKVZaHDS+9/vJ0XF5c2PC8no3Ojw0qhvYdszTsEIsizhn4BPOju9cf7D+/uU4GpEJosboVsInIKzIy8rknkdU3i4uG9Gh7fvjs077AyvPewqqySt46YdxianRbecwiVQ//uycTFxgT0nUSHIIsgH5gRLoHuwCQzq3X3PwWYSUQiqFtKJ84dmMm5Aw/NO+w9UEtx+a7wxHRoD+KZ9zdwoDY075AQG8PAnikMzkpjSK9UBmelMbhXKt21xkcWSOcAAAeCSURBVFKLCawI3L3fwc/N7PfAn1UCItEnKSGOcX26MK5Pl4bHauvq+bhiD6vKK1m9eRery3cxb20FLxSVNIzpntIpXAyHyuG0Hil0itPE9ImK5Omj04HzgO5mVgI8DMQDuPuTkXpdEWn/4mJjOD0rldOzUg97fMeeA6zeXMXq8l2hPzfv4tn3N7A/vPdwcGL6YDEMCf+Zlaa5h2PRBWUi0q7V1TufbN/TUA7F4T9LPt3XMCa9czyDs1IZ0it0OuvgXmkM6plCUkL0LK6gG9OISIcV2gtIYUBmCpeOPDQxXVVdw5rNuyjevIvV5aG9h+cKN7HnQB0QWk6jb7fkww4tDclKI7dLZ2Ki7KI4FYGIdEhpifGfubdDfb1TunMfxeFiOHiY6bWVmxvOXEpOiOX08F7DkPCfp2elktaBV2rVoSERiXp7D9Ty0ZbdDYeWDhZF5b6ahjF5XTsztFcaQ3ulM6RXKkOz08jJ6Nxu5h50aEhE5BiSEuIYlZfBqLyMhsfcnc1V1awOn9paXB5aUuONVYeue0hLjGNoduhiuqG9QldMD+yRSkJc+7ruQUUgItIEM6NXemd6pXduuKc0hPYeVm/exaqyQ+UwY8Em9tWE5h7iY0NzFgcvjBsavuq6S3LbXVJDRSAicgKSEuIY27sLY3sfuu7h4JlLxeHVWleVVzHvo23MLjq0pEZ2emJozyH70N5DXpekNjExrSIQETlFjc9cumxkdsPj23bvP6wcisureGdNBXX1oWNLyQmxh5XDkPDEdGuv1qrJYhGRVlRdU8eaLYcfWiou38Xu/bUAxITvEndkQWSmntqSGposFhFpIxLjYxmZm8HI3EMT0/X1zqZP9x6291D4yQ7mNLq/dGZqJ+44tz+3T+jf4plUBCIiAYuJMfp0S6ZPt+TDVmvdufdAw13iVpVX0SMtMgvtqQhERNqojKQEzh7QnbMHdI/o67Svk11FRKTFqQhERKKcikBEJMqpCEREopyKQEQkyqkIRESinIpARCTKqQhERKJcu1tryMwqgA0n+fTuwLYWjNPe6f04nN6PQ/ReHK4jvB993D2zqQ3trghOhZkVHm3RpWik9+Nwej8O0XtxuI7+fujQkIhIlFMRiIhEuWgrgqlBB2hj9H4cTu/HIXovDteh34+omiMQEZHPirY9AhEROYKKQEQkykVNEZjZxWb2oZmtNbPvBJ0nSGaWZ2Z/M7NVZrbSzO4JOlPQzCzWzBab2Z+DzhI0M8sws+fNbLWZFZvZWUFnCoqZ/XP438gKM5tuZolBZ4qEqCgCM4sFngAuAYYCN5jZ0GBTBaoWuN/dhwLjgbui/P0AuAcoDjpEG/FL4DV3HwyMIkrfFzPLAb4F5Lv7cCAWmBJsqsiIiiIAzgDWuvs6dz8AzACuDDhTYNy93N2Lwp/vIvQPPSfYVMExs1zgUuC3QWcJmpmlAxOApwDc/YC77ww2VaDigM5mFgckAWXHGd8uRUsR5ACbGv29hCj+wdeYmfUFxgDzg00SqF8A3wbqgw7SBvQDKoDfhQ+V/dbMkoMOFQR3LwV+BmwEyoFKd38j2FSRES1FIE0wsxTgBeBed68KOk8QzOwyYKu7Lwo6SxsRB4wFfu3uY4A9QFTOqZlZF0JHDvoB2UCymd0UbKrIiJYiKAXyGv09N/xY1DKzeEIlMM3dZwedJ0DnAFeY2SeEDhmeb2b/G2ykQJUAJe5+cA/xeULFEI2+AKx39wp3rwFmA2cHnCkioqUIFgIDzayfmSUQmvCZE3CmwJiZEToGXOzujwSdJ0ju/l13z3X3voT+v/iru3fI3/qaw903A5vM7PTwQxcAqwKMFKSNwHgzSwr/m7mADjpxHhd0gNbg7rVm9k3gdUIz/0+7+8qAYwXpHOBmYLmZLQk/9j13fzXATNJ23A1MC//StA64LeA8gXD3+Wb2PFBE6Ey7xXTQpSa0xISISJSLlkNDIiJyFCoCEZEopyIQEYlyKgIRkSinIhARiXIqApFWZGbnaYVTaWtUBCIiUU5FINIEM7vJzBaY2RIz+034fgW7zezR8Pr0b5tZZnjsaDP7wMyWmdmL4TVqMLPTzOwtM1tqZkVmNiD85VMarfc/LXzVqkhgVAQiRzCzIcBk4Bx3Hw3UATcCyUChuw8D3gUeDj/lWeBBdx8JLG/0+DTgCXcfRWiNmvLw42OAewndG6M/oSu9RQITFUtMiJygC4BxwMLwL+udga2ElqmeGR7zv8Ds8Pr9Ge7+bvjxZ4DnzCwVyHH3FwHcvRog/PUWuHtJ+O9LgL7AvMh/WyJNUxGIfJYBz7j7dw970Oz7R4w72fVZ9jf6vA79O5SA6dCQyGe9DVxrZj0AzKyrmfUh9O/l2vCYLwPz3L0S+NTMzg0/fjPwbvjObyVm9qXw1+hkZkmt+l2INJN+ExE5gruvMrN/Ad4wsxigBriL0E1azghv20poHgHgn4Anwz/oG6/WeTPwGzP7t/DXuK4Vvw2RZtPqoyLNZGa73T0l6BwiLU2HhkREopz2CEREopz2CEREopyKQEQkyqkIRESinIpARCTKqQhERKLc/wf8ipTN5xDH4wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_model_loss(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIRKXWsWHLyz"
      },
      "source": [
        "## Output\n",
        "Now that are model is trained and readied, its time to use it\n",
        "The next snippet uses our RNN model and generate some text!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "MIVZwI7ufnBk"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states\n",
        "    \n",
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NefKWCZ6ftnu",
        "outputId": "9a47be5a-049e-4e77-a1c4-16471b2ac4cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joyce: now country set crossles hospitality hand anrows misers suturity said coming uspers leave hes cobrain telegraph late touches like man want pounds exnibbed purchased lips office put home being fox feignd nobods never cuase ehately long wrecked foostate possibly atepred him live anything plemie lovely stage victoing barney kiss hair struggle thoremall character shoulder glanced jies certain extendion life went teach see grave ireland black cool was life chiteen how think sir brought upstair miscreabily long you away heal liverpoke that armsback lelt ask woman remove hall owes again you ill go said mr holo fading round clag human fingers rapidly anyway light game decided van minds easily written following white right faces put bit cat recloning concert boots existence tenrest beceated allowing cowsides inner obviating pedished relation wrence mulligan gates cup browners possess castole then bread skin assitation new unable remark things elevated dedalus constablesion vienness arrive prope \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.51639723777771\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Joyce: '])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNOZh7WO1Rqz"
      },
      "source": [
        "## LSTM Basded Model\n",
        "keras.layers.LSTM -> keras.layers.Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_book_df():\n",
        "  book_list = [fold for file, der, fold in os.walk(\"book_project/\")][0]\n",
        "  books_df = pandas.DataFrame(columns=[\"book_name\", \"text\"])\n",
        "  for book in book_list:\n",
        "      with open(f\"book_project/{book}\", encoding=\"utf-8\") as book_file:\n",
        "          cleaned = clean_book(book_file)\n",
        "          books_df = books_df.append({\"book_name\": book, \"text\": cleaned}, ignore_index=True)\n",
        "  books_df[\"cleaned_description\"] = books_df.apply(lambda book_row: remove_non_ascii(book_row), axis=1)\n",
        "  return books_df\n",
        "\n",
        "\n",
        "books_df = create_book_df()\n",
        "\n",
        "all_words = \"\"\n",
        "for index, row in books_df.iterrows():\n",
        "    all_words += row[\"cleaned_description\"]\n",
        "\n",
        "vocab = sorted(set(all_words))\n",
        "print(f\"{len(vocab)} unique characters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3XqrcpF3mUh",
        "outputId": "0107b3b2-bf30-4bbb-fbca-679592aade95"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Corpus length:\", len(all_words))\n",
        "\n",
        "chars = sorted(list(set(all_words)))\n",
        "print(\"Total chars:\", len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(all_words) - maxlen, step):\n",
        "    sentences.append(all_words[i : i + maxlen])\n",
        "    next_chars.append(all_words[i + maxlen])\n",
        "print(\"Number of sequences:\", len(sentences))\n",
        "\n",
        "x = numpy.zeros((len(sentences), maxlen, len(chars)), dtype=numpy.bool)\n",
        "y = numpy.zeros((len(sentences), len(chars)), dtype=numpy.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCyg0w_m0bEt",
        "outputId": "dbaea933-77aa-41f8-9c07-abc07de06c4b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus length: 2500877\n",
            "Total chars: 82\n",
            "Number of sequences: 833613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_based_model(rnn_units, loss, optimizer):\n",
        "  model = keras.Sequential(\n",
        "    [ keras.Input(shape=(maxlen, len(chars))),\n",
        "      LSTM(rnn_units),\n",
        "      Dense(len(chars), activation=\"softmax\"),\n",
        "    ])\n",
        "  model.compile(loss=loss, optimizer=optimizer)\n",
        "  return model"
      ],
      "metadata": {
        "id": "YAMNHqD11J2n"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_units = 128\n",
        "learning_rate=0.0005\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "loss=\"categorical_crossentropy\"\n",
        "model = LSTM_based_model(rnn_units, loss, optimizer)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tpygJDh4KNM",
        "outputId": "1b78850d-bf50-4a4b-e49b-7489850d6ec4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               108032    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 82)                10578     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118,610\n",
            "Trainable params: 118,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  # helper function to sample an index from a probability array\n",
        "  preds = numpy.asarray(preds).astype(\"float64\")\n",
        "  preds = numpy.log(preds) / temperature\n",
        "  exp_preds = numpy.exp(preds)\n",
        "  preds = exp_preds / numpy.sum(exp_preds)\n",
        "  probas = numpy.random.multinomial(1, preds, 1)\n",
        "  return numpy.argmax(probas)"
      ],
      "metadata": {
        "id": "Y0prm6yZ1d_R"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UtesRgywdWt",
        "outputId": "d8f4f159-fd25-460e-8dd2-672e69e138a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6513/6513 [==============================] - 70s 11ms/step - loss: 1.8976\n",
            "Epoch 2/10\n",
            "6513/6513 [==============================] - 73s 11ms/step - loss: 1.8347\n",
            "Epoch 3/10\n",
            "6513/6513 [==============================] - 72s 11ms/step - loss: 1.7880\n",
            "Epoch 4/10\n",
            "6513/6513 [==============================] - 71s 11ms/step - loss: 1.7528\n",
            "Epoch 5/10\n",
            "6513/6513 [==============================] - 71s 11ms/step - loss: 1.7243\n",
            "Epoch 6/10\n",
            "6513/6513 [==============================] - 71s 11ms/step - loss: 1.7024\n",
            "Epoch 7/10\n",
            "6513/6513 [==============================] - 70s 11ms/step - loss: 1.6842\n",
            "Epoch 8/10\n",
            "6513/6513 [==============================] - 71s 11ms/step - loss: 1.6683\n",
            "Epoch 9/10\n",
            "6513/6513 [==============================] - 71s 11ms/step - loss: 1.6553\n",
            "Epoch 10/10\n",
            "6513/6513 [==============================] - 72s 11ms/step - loss: 1.6435\n",
            "<keras.callbacks.History object at 0x7f8f37f22f10>\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "EPOCHS = 10\n",
        "batch_size = 128\n",
        "\n",
        "history = model.fit(x, y, batch_size=batch_size, epochs=EPOCHS)\n",
        "print(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model_loss(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "dhrnxaQyAd6Y",
        "outputId": "1613708b-621a-4c51-8d6b-384d0b410e4a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_index = random.randint(0, len(all_words) - maxlen - 1)\n",
        "for diversity in [0.2]:\n",
        "    print(\"...Diversity:\", diversity)\n",
        "\n",
        "    generated = \"\"\n",
        "    sentence = all_words[start_index : start_index + maxlen]\n",
        "    print('...Generating with seed: \"' + sentence + '\"')\n",
        "\n",
        "    for i in range(1000):\n",
        "        x_pred = numpy.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_indices[char]] = 1.0\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, diversity)\n",
        "        next_char = indices_char[next_index]\n",
        "        sentence = sentence[1:] + next_char\n",
        "        generated += next_char\n",
        "\n",
        "    print(\"...Generated: \", generated)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uxZ4Tnv6dmT",
        "outputId": "2b8c14d7-2267-4fa6-82e0-777b4c3f0bcd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...Diversity: 0.2\n",
            "...Generating with seed: \"amber, Black Rod,\n",
            "Deputy Garter, Gold St\"\n",
            "...Generated:  ephen said. They would the morning and the some of the sear of the stand of the soul and the tries of the state of the stander of the counter of the took of the strange of the country of the standing of the speen of the the reason of the speak of the stand of the stand of the stand of the stand of the stander of the course and the stand of the partion of the counter of the first of the constant of the stand of the words of the stand of the could and the said of the suns of the some of the sale of the shoulder and the soul and the stand of the constant the contract of the stand of the counter of the stander of the stand of the stand of the partain of the bright of the stand of the stand of the stander of the stand of the constant to the the soul and the first the course the stander of the stands of the stander of the stand of the sear of the stand of the stand of the soul of his eyes of the part of the stand of the stand of the body and the stand of the stare of the sail\n",
            "of his seemed t\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_units = 256\n",
        "learning_rate=0.0001\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "loss=\"categorical_crossentropy\"\n",
        "model = LSTM_based_model(rnn_units, loss, optimizer)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAx4g-ZFFVOP",
        "outputId": "ca02bb24-dac8-42ab-c59a-0195687b96be"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 256)               347136    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 82)                21074     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 368,210\n",
            "Trainable params: 368,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "epochs = 10\n",
        "sub_epoch = 1\n",
        "batch_size = 128\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.fit(x, y, batch_size=batch_size, epochs=sub_epoch)\n",
        "  print()\n",
        "  print(\"Generating text after epoch: %d\" % epoch)\n",
        "\n",
        "  start_index = random.randint(0, len(all_words) - maxlen - 1)\n",
        "  for diversity in [0.3]:\n",
        "      print(\"...Diversity:\", diversity)\n",
        "\n",
        "      generated = \"\"\n",
        "      sentence = all_words[start_index : start_index + maxlen]\n",
        "      print('...Generating with seed: \"' + sentence + '\"')\n",
        "\n",
        "      for i in range(400):\n",
        "          x_pred = numpy.zeros((1, maxlen, len(chars)))\n",
        "          for t, char in enumerate(sentence):\n",
        "              x_pred[0, t, char_indices[char]] = 1.0\n",
        "          preds = model.predict(x_pred, verbose=0)[0]\n",
        "          next_index = sample(preds, diversity)\n",
        "          next_char = indices_char[next_index]\n",
        "          sentence = sentence[1:] + next_char\n",
        "          generated += next_char\n",
        "\n",
        "      print(\"...Generated: \", generated)\n",
        "      print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCiRMP61FJ_D",
        "outputId": "f4a124bb-4e8b-4283-c3de-f0437a9166cb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6513/6513 [==============================] - 109s 16ms/step - loss: 2.7456\n",
            "\n",
            "Generating text after epoch: 0\n",
            "...Diversity: 0.3\n",
            "...Generating with seed: \",\n",
            "under its screen, his eyes looked quic\"\n",
            "...Generated:  e the rere the ware ante the the he the the ther and wathe s and the her and and the and and wore the whe the ware sor the the sore the ther the the the the s and the berere and the sare the the ther fore his and the sore the the sale the he lout the the sint an the the and sithe an the the and the soithe the ther and the the the sare the war ang out and the care the the the the the sare terer and\n",
            "\n",
            "6513/6513 [==============================] - 101s 15ms/step - loss: 2.3602\n",
            "\n",
            "Generating text after epoch: 1\n",
            "...Diversity: 0.3\n",
            "...Generating with seed: \"\n",
            "the porters up in him so says I just to\"\n",
            "...Generated:   the call at the ther wath the the the sand the couthe the wathe the cour on the pangert the ald and and and the and whe has southe souce the calle the cand of and soing the sither sad the sered and the sing the sald the the simen the paine for and the dat the lang and of the sand and the coure and the sing the sille soud sile that and and the the ther wint and the paren and the singer suthe sald \n",
            "\n",
            "6513/6513 [==============================] - 88s 14ms/step - loss: 2.2378\n",
            "\n",
            "Generating text after epoch: 2\n",
            "...Diversity: 0.3\n",
            "...Generating with seed: \" to a\n",
            "military review in the park.\n",
            "\n",
            "The \"\n",
            "...Generated:  wass wat he wat the hat he sad soud the bean the surpe to the brous and the cound for his and wat the could the all the same the has hear to the sall wather and won he wat the far the could the douth the was and she blow the sad the the pare the and the sald and wath the has wat the ward of the was store han the said the pand of the sall cound the wist the sall the last of the mand of the parse an\n",
            "\n",
            "6513/6513 [==============================] - 112s 17ms/step - loss: 2.1517\n",
            "\n",
            "Generating text after epoch: 3\n",
            "...Diversity: 0.3\n",
            "...Generating with seed: \"Tell him a tale of woe about arrears\n",
            "of \"\n",
            "...Generated:  the sours of the parse the the was he was the waid dean the and and he was the hat the fore the said and the cand of the minter and and the for the store stome the was and the cours and the coust of the his to the wather him the ward hat he beat of the seant in the coull and to the stien the sart of the hand and the sare of the sind on the sagre the was the the gat of the could and wat the the cou\n",
            "\n",
            "6513/6513 [==============================] - 87s 13ms/step - loss: 2.0845\n",
            "\n",
            "Generating text after epoch: 4\n",
            "...Diversity: 0.3\n",
            "...Generating with seed: \"o people like that nowadays full up of e\"\n",
            "...Generated:  res the ward of the was was and to the beat of the said the corles of the couther and the\n",
            "sinters and the pares and he was she pores of the rast of the cond of the reat and the ond he had was the reas the fare of the beat of the rainted and the canter of the cound and a the beat of a minting of the reat of the gores and the sinter of the singhe of the rought and the panting and the said of the cou\n",
            "\n",
            "6513/6513 [==============================] - 89s 14ms/step - loss: 2.0301\n",
            "\n",
            "Generating text after epoch: 5\n",
            "...Diversity: 0.3\n",
            "...Generating with seed: \"heyll all\n",
            "know at 50 they dont know how \"\n",
            "...Generated:  a man the fore of the rimet on the sinter and the rount of his sind the lood of the siont of a the could of the reating her of the was of the corlon of the beat of the corse the said the her and the fored and the fill of a sour and the fore the back of the said of the said of her and the had the courd of the reat and the fore his and the had and the back the rowe the pores on the cores of the corl\n",
            "\n",
            "6513/6513 [==============================] - 87s 13ms/step - loss: 1.9853\n",
            "\n",
            "Generating text after epoch: 6\n",
            "...Diversity: 0.3\n",
            "...Generating with seed: \" too. Attract men, small thing like that\"\n",
            "...Generated:   was the come of the rome to be the bery the could and stat and she had and the beal of the said and the could and the said of the sand of the rome of her and the with a was the rist of the her was a cond was in the some of the come of the called in the could and the sould of the some of the reat of the round and the rould and the sind he was not and the lat lith and listed his have and the has fo\n",
            "\n",
            "6513/6513 [==============================] - 89s 14ms/step - loss: 1.9468\n",
            "\n",
            "Generating text after epoch: 7\n",
            "...Diversity: 0.3\n",
            "...Generating with seed: \" Francis Dennehy, 17\n",
            "Church street, Enni\"\n",
            "...Generated:  nghan as a bect of the course of her the said and the pare and still the said the pane of the mant was the conder of the stull of the coment of the bead of the come and said the can of the care and\n",
            "me of the fire of the still was a dind and the sour and and the care of the store of his\n",
            "fare and the seart of the core and the prees and the said the panter and the said of the still his for her had th\n",
            "\n",
            "6513/6513 [==============================] - 87s 13ms/step - loss: 1.9139\n",
            "\n",
            "Generating text after epoch: 8\n",
            "...Diversity: 0.3\n",
            "...Generating with seed: \"hough shes a factory lass\n",
            "     And wears\"\n",
            "...Generated:   the marting on ore son a to the sime of the cond of the book of the reat of the wast of the sine of the floom of the some of the ber and of the said and the bect of the stare of the sand and the said the said the stile of the said of the sear\n",
            "she the said the man of the sand he said the stare of the sime of the was and the sid the sement of the stan of the sume of the fire and the scoul of the fa\n",
            "\n",
            "6513/6513 [==============================] - 87s 13ms/step - loss: 1.8849\n",
            "\n",
            "Generating text after epoch: 9\n",
            "...Diversity: 0.3\n",
            "...Generating with seed: \" at half past four.\n",
            "Dust. Shark liver oi\"\n",
            "...Generated:  t of the pectors of the courte of a secting and the stall of and the could of the stanter of the street was and her sone he had booked her to see the stare of the cand of the the said the some to the stroes of the\n",
            "stiles of his not with a shaw the prape of the stopers of his souther.\n",
            "\n",
            "He was a pooner comes and soursed his book and to the sand of the corners of the sand of the compors of the plose \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = [0,1,2,3,4,5,6,7,8,9]\n",
        "losses = [2.7456, 2.3602, 2.2378, 2.1517, 2.0845, 2.0301, 1.9853, 1.9468, 1.9139, 1.8849]\n",
        "plt.plot(index, losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RMifmYbAOt6e",
        "outputId": "c4395dbc-60d4-46ab-afb0-7148368d65ea"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_units = 1024\n",
        "learning_rate=0.00001\n",
        "batch_size=64\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "loss=\"categorical_crossentropy\"\n",
        "model = LSTM_based_model(rnn_units, loss, optimizer)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjJVelCNQ4cR",
        "outputId": "16e1c356-f9c2-42e5-fa50-c36119c9d351"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 1024)              4534272   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 82)                84050     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,618,322\n",
            "Trainable params: 4,618,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history =model.fit(x, y, batch_size=batch_size, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "kFpv3c99RAMZ",
        "outputId": "818539c2-eb9a-4f89-cf96-26cf8bbe43b7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "13026/13026 [==============================] - 376s 29ms/step - loss: 3.0656\n",
            "Epoch 2/10\n",
            "13026/13026 [==============================] - 374s 29ms/step - loss: 2.7436\n",
            "Epoch 3/10\n",
            " 5797/13026 [============>.................] - ETA: 3:27 - loss: 2.5851"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-b6f80884c273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wrP5am3Hk9_"
      },
      "source": [
        "# Expirements\n",
        "Starting from our data pre-processing, lets review how changes in the data affect our model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZxAp9gMH2W6"
      },
      "source": [
        "## Do not remove punctuations\n",
        "Exploring our model output with puctuations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_book_df():\n",
        "  book_list = [fold for file, der, fold in os.walk(\"book_project/\")][0]\n",
        "  books_df = pandas.DataFrame(columns=[\"book_name\", \"text\"])\n",
        "  for book in book_list:\n",
        "      with open(f\"book_project/{book}\", encoding=\"utf-8\") as book_file:\n",
        "          cleaned = clean_book(book_file)\n",
        "          books_df = books_df.append({\"book_name\": book, \"text\": cleaned}, ignore_index=True)\n",
        "  books_df[\"cleaned_description\"] = books_df.apply(lambda book_row: remove_non_ascii(book_row), axis=1)\n",
        "  books_df[\"cleaned_description\"] = books_df.apply(lambda book_row: make_lower_case(book_row), axis=1)\n",
        "  books_df[\"cleaned_description\"] = books_df.cleaned_description.apply(remove_stop_words)\n",
        "  books_df[\"cleaned_description\"] = books_df.cleaned_description.apply(remove_multiple_spaces)\n",
        "  return books_df\n",
        "\n",
        "books_df = create_book_df()\n",
        "\n",
        "all_words = \"\"\n",
        "for index, row in books_df.iterrows():\n",
        "    all_words += row[\"cleaned_description\"]\n",
        "\n",
        "vocab = sorted(set(all_words))\n",
        "print(f\"{len(vocab)} unique characters\")\n",
        "\n",
        "from collections import Counter\n",
        "all_words_set = Counter(all_words.split())\n",
        "print(f\"Unique words: {len(all_words_set)}\")\n",
        "print(f\"Most frequnetly used words: {all_words_set.most_common(10)}\")\n",
        "top_ten_words = 0\n",
        "for word in all_words_set.most_common(10):\n",
        "  top_ten_words+= word[1]\n",
        "\n",
        "top_twenty_words = 0\n",
        "for word in all_words_set.most_common(20):\n",
        "  top_twenty_words+= word[1]\n",
        "print(f\"Top 10 words are {top_ten_words/len(all_words_set)*100}% of all words\")\n",
        "print(f\"Top 20 words are {top_twenty_words/len(all_words_set)*100}% of all words\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ANSDv3BT3ZFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj0Cifa5H1kc",
        "outputId": "626af9bb-5226-42a3-ebd3-aba27e33f89f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54 unique characters\n",
            "Unique words: 54264\n",
            "Most frequnetly used words: [('mr', 1454), ('said', 1418), ('like', 1117), ('one', 1015), ('would', 938), ('old', 730), ('little', 647), ('said.', 629), ('could', 614), ('stephen', 554)]\n",
            "Top 10 words are 16.799351319475157% of all words\n",
            "Top 20 words are 25.630252100840334% of all words\n",
            "(128, 100, 55) # (batch_size, sequence_length, vocab_size)\n",
            "Prediction shape:  (128, 100, 55)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.005956, shape=(), dtype=float32)\n",
            "Epoch 1/10\n",
            "134/134 [==============================] - 11s 62ms/step - loss: 2.7231\n",
            "Epoch 2/10\n",
            "134/134 [==============================] - 9s 61ms/step - loss: 2.2304\n",
            "Epoch 3/10\n",
            "134/134 [==============================] - 9s 61ms/step - loss: 2.0219\n",
            "Epoch 4/10\n",
            "134/134 [==============================] - 9s 61ms/step - loss: 1.8457\n",
            "Epoch 5/10\n",
            "134/134 [==============================] - 9s 61ms/step - loss: 1.7262\n",
            "Epoch 6/10\n",
            "134/134 [==============================] - 10s 66ms/step - loss: 1.6471\n",
            "Epoch 7/10\n",
            "134/134 [==============================] - 10s 62ms/step - loss: 1.5887\n",
            "Epoch 8/10\n",
            "134/134 [==============================] - 10s 63ms/step - loss: 1.5440\n",
            "Epoch 9/10\n",
            "134/134 [==============================] - 9s 61ms/step - loss: 1.5054\n",
            "Epoch 10/10\n",
            "134/134 [==============================] - 10s 62ms/step - loss: 1.4700\n",
            "Joyce: past: _(he stood.)_ flankly tockets know that. god knew for. jealousy, says jer. look wipe rid brush green looks. yours like get back glances. fact? says he. meant, sir. fixed miss high reach entered? poidle, also. rasinion here. want lib, know, fellow: workingtons one: hope like glance all, quickly, whores. broke triflely. encounted father went room. made look. passed away murmured doorway went waters. marian sixpencaplus. gradual cash, want trelular amang mary: happened me? chair usell wrong crossed spinning hat and, spoke dock! end think me. see chamber? little man. man. turn soul body injerestor, more? teption man. otherwise. may either going suddenly working rame woman slice _black dusky.)_ say it! broke pe, blood road lencth. rob? f. c.... haggy love seen know urging like am servedingjeat hell. history, lenehan catch eside lynch. fares. fighting cavage. listened too, mattered first. came gaze, rise eubody, hadnt left out. hell lionel constable. mr altarition particular face cheek \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.052944183349609\n"
          ]
        }
      ],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(all_words, 'UTF-8'))\n",
        "\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "\n",
        "seq_length = 100\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "    \n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "  \n",
        "dataset = sequences.map(split_input_target)\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        " # Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "model_exp1 = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model_exp1(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)\n",
        "\n",
        "\n",
        "model_exp1.compile(optimizer='adam', loss=loss)\n",
        "history = model_exp1.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
        "one_step_model = OneStep(model_exp1, chars_from_ids, ids_from_chars)\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Joyce: '])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the following pheno - \n",
        "Top 10 words are now ~16% of all words, while without puncatuations we see that\n",
        "top 10 words account for ~34% of all words.\n",
        "This is clear indication of Joyce's writing style.\n",
        "\n",
        "Lets continue explorint this direction."
      ],
      "metadata": {
        "id": "IezZD5UUk0sV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhz5-GJ6IM33"
      },
      "source": [
        "## Do not remove stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STmpqP_uISbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc2d001-1f8f-4b5a-d314-bd83e8283bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55 unique characters\n",
            "Unique words: 54399\n",
            "Most frequnetly used words: [('the', 25794), ('of', 13517), ('and', 13096), ('a', 10418), ('to', 9143), ('in', 7685), ('he', 7370), ('his', 6402), ('i', 4672), ('was', 4379)]\n",
            "Top 10 words are 188.37846283939044% of all words\n",
            "Top 20 words are 245.19384547510063% of all words\n",
            "(128, 100, 56) # (batch_size, sequence_length, vocab_size)\n",
            "Prediction shape:  (128, 100, 56)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.024408, shape=(), dtype=float32)\n",
            "Epoch 1/10\n",
            "192/192 [==============================] - 14s 60ms/step - loss: 2.5824\n",
            "Epoch 2/10\n",
            "192/192 [==============================] - 13s 60ms/step - loss: 2.0062\n",
            "Epoch 3/10\n",
            "192/192 [==============================] - 13s 60ms/step - loss: 1.7715\n",
            "Epoch 4/10\n",
            "192/192 [==============================] - 13s 63ms/step - loss: 1.6323\n",
            "Epoch 5/10\n",
            "192/192 [==============================] - 13s 60ms/step - loss: 1.5449\n",
            "Epoch 6/10\n",
            "192/192 [==============================] - 13s 61ms/step - loss: 1.4845\n",
            "Epoch 7/10\n",
            "192/192 [==============================] - 13s 60ms/step - loss: 1.4362\n",
            "Epoch 8/10\n",
            "192/192 [==============================] - 13s 60ms/step - loss: 1.3938\n",
            "Epoch 9/10\n",
            "192/192 [==============================] - 13s 60ms/step - loss: 1.3574\n",
            "Epoch 10/10\n",
            "192/192 [==============================] - 13s 60ms/step - loss: 1.3246\n",
            "Joyce: second case, mr bloom too into the wild unducking million suit, templa\n",
            "enthusiasch, and the brannantkerhouse of the venigins and smiles and\n",
            "scratches, i know, eppresses, lit and his buttoning clergymans uninour beds,\n",
            "twelve need. lady out of the bloodshouc, moses\n",
            "heart assurtly. monoured that bloodyth to kneel shop by two in the\n",
            "country earth. and the lamp with me. father: trembling my\n",
            "love is he ideal. i want to be his errents? bloom: im herse. pass i aught. jaud left in my consonel joysun! kin, malachi.\n",
            "bertha.\n",
            "[_lautly._] i have a freediff, how. if that was\n",
            "taking these could i chap? talk down, remind you, intervasis, the man whose shoes\n",
            "allmed with grey billys catcy today thee all liarping lights the diserographical prior and there was none\n",
            "upon my side of his own women and wysens hit her ears. proposea on\n",
            "to the point of arms gaityfully: whet you get them ug\n",
            "cold and sea, brigid.\n",
            "task all, now. they were not telling my clouded. work her hand? glory was the sun,\n",
            "pappia, and the wis \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.3521997928619385\n"
          ]
        }
      ],
      "source": [
        "def create_book_df():\n",
        "  book_list = [fold for file, der, fold in os.walk(\"book_project/\")][0]\n",
        "  books_df = pandas.DataFrame(columns=[\"book_name\", \"text\"])\n",
        "  for book in book_list:\n",
        "      with open(f\"book_project/{book}\", encoding=\"utf-8\") as book_file:\n",
        "          cleaned = clean_book(book_file)\n",
        "          books_df = books_df.append({\"book_name\": book, \"text\": cleaned}, ignore_index=True)\n",
        "  books_df[\"cleaned_description\"] = books_df.apply(lambda book_row: remove_non_ascii(book_row), axis=1)\n",
        "  books_df[\"cleaned_description\"] = books_df.apply(lambda book_row: make_lower_case(book_row), axis=1)\n",
        "  books_df[\"cleaned_description\"] = books_df.cleaned_description.apply(remove_multiple_spaces)\n",
        "  return books_df\n",
        "\n",
        "\n",
        "books_df = create_book_df()\n",
        "\n",
        "all_words = \"\"\n",
        "for index, row in books_df.iterrows():\n",
        "    all_words += row[\"cleaned_description\"]\n",
        "\n",
        "vocab = sorted(set(all_words))\n",
        "print(f\"{len(vocab)} unique characters\")\n",
        "\n",
        "from collections import Counter\n",
        "all_words_set = Counter(all_words.split())\n",
        "print(f\"Unique words: {len(all_words_set)}\")\n",
        "print(f\"Most frequnetly used words: {all_words_set.most_common(10)}\")\n",
        "top_ten_words = 0\n",
        "for word in all_words_set.most_common(10):\n",
        "  top_ten_words+= word[1]\n",
        "\n",
        "top_twenty_words = 0\n",
        "for word in all_words_set.most_common(20):\n",
        "  top_twenty_words+= word[1]\n",
        "print(f\"Top 10 words are {top_ten_words/len(all_words_set)*100}% of all words\")\n",
        "print(f\"Top 20 words are {top_twenty_words/len(all_words_set)*100}% of all words\")\n",
        "\n",
        "\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "\n",
        "\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(all_words, 'UTF-8'))\n",
        "\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "\n",
        "seq_length = 100\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "    \n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "  \n",
        "dataset = sequences.map(split_input_target)\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        " # Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "model_exp1 = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model_exp1(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)\n",
        "\n",
        "\n",
        "model_exp1.compile(optimizer='adam', loss=loss)\n",
        "history = model_exp1.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
        "one_step_model = OneStep(model_exp1, chars_from_ids, ids_from_chars)\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Joyce: '])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation\n",
        "\n",
        "The following is an input from a previous run of the model:"
      ],
      "metadata": {
        "id": "WddHjfUAne9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joyce: second case, mr bloom too into the wild unducking million suit, templa\n",
        "enthusiasch, and the brannantkerhouse of the venigins and smiles and\n",
        "scratches, i know, eppresses, lit and his buttoning clergymans uninour beds,\n",
        "twelve need. lady out of the bloodshouc, moses\n",
        "heart assurtly. monoured that bloodyth to kneel shop by two in the\n",
        "country earth. and the lamp with me. father: trembling my\n",
        "love is he ideal. i want to be his errents? bloom: im herse. pass i aught. jaud left in my consonel joysun! kin, malachi.\n",
        "\n",
        "bertha.\n",
        "\n",
        "[_lautly._] i have a freediff, how. \n",
        "if that was\n",
        "taking these could i chap? talk down, remind you, intervasis, the man whose shoes\n",
        "allmed with grey billys catcy today thee all liarping lights the diserographical prior and there was none\n",
        "upon my side of his own women and wysens hit her ears. proposea on\n",
        "to the point of arms gaityfully: whet you get them ug\n",
        "cold and sea, brigid.\n",
        "task all, now. they were not telling my clouded. work her hand? glory was the sun,\n",
        "pappia, and the wis \n"
      ],
      "metadata": {
        "id": "qvLrzPlnnnwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the content is very sproadic and contains spelling errors, the strucutre is highly indicative of the author, for example the following text from Julysses -"
      ],
      "metadata": {
        "id": "uD3bjbjDnyj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_(She glides away crookedly. Mrs Breen in mans frieze overcoat with\n",
        "loose bellows pockets, stands in the causeway, her roguish eyes\n",
        "wideopen, smiling in all her herbivorous buckteeth.)_\n",
        "\n",
        "MRS BREEN: Mr...\n",
        "\n",
        "BLOOM: _(Coughs gravely.)_ Madam, when we last had this pleasure by\n",
        "letter dated the sixteenth instant...\n",
        "\n",
        "MRS BREEN: Mr Bloom! You down here in the haunts of sin! I caught you\n",
        "nicely! Scamp!\n",
        "\n",
        "BLOOM: _(Hurriedly.)_ Not so loud my name. Whatever do you think of me?"
      ],
      "metadata": {
        "id": "cBfQwTFtoH8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using our expeirments & Observeations\n",
        "We found the author extensive use of punctuations marks, spaces is very notiable in his writing.\n",
        "To remain truth to the writing, our model should take account of this matter."
      ],
      "metadata": {
        "id": "7aVSibuColiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_book_df():\n",
        "  book_list = [fold for file, der, fold in os.walk(\"book_project/\")][0]\n",
        "  books_df = pandas.DataFrame(columns=[\"book_name\", \"text\"])\n",
        "  for book in book_list:\n",
        "      with open(f\"book_project/{book}\", encoding=\"utf-8\") as book_file:\n",
        "          cleaned = clean_book(book_file)\n",
        "          books_df = books_df.append({\"book_name\": book, \"text\": cleaned}, ignore_index=True)\n",
        "  books_df[\"cleaned_description\"] = books_df.apply(lambda book_row: remove_non_ascii(book_row), axis=1)\n",
        "  return books_df\n",
        "\n",
        "\n",
        "books_df = create_book_df()\n",
        "\n",
        "all_words = \"\"\n",
        "for index, row in books_df.iterrows():\n",
        "    all_words += row[\"cleaned_description\"]\n",
        "\n",
        "vocab = sorted(set(all_words))\n",
        "all_words_set = Counter(all_words.split())\n",
        "\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(all_words, 'UTF-8'))\n",
        "\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "\n",
        "seq_length = 100\n",
        "BATCH_SIZE = 20\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "    \n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "  \n",
        "dataset = sequences.map(split_input_target)\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "model_exp1 = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model_exp1(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "\n",
        "model_exp1.compile(optimizer='adam', loss=loss)\n",
        "history = model_exp1.fit(dataset, epochs=EPOCHS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8QbJpXeok6F",
        "outputId": "f7eac433-cf05-4b97-d111-82381c52d73f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 100, 83) # (batch_size, sequence_length, vocab_size)\n",
            "Epoch 1/10\n",
            "1238/1238 [==============================] - 35s 27ms/step - loss: 1.9684\n",
            "Epoch 2/10\n",
            "1238/1238 [==============================] - 33s 27ms/step - loss: 1.5352\n",
            "Epoch 3/10\n",
            "1238/1238 [==============================] - 34s 27ms/step - loss: 1.4255\n",
            "Epoch 4/10\n",
            "1238/1238 [==============================] - 33s 27ms/step - loss: 1.3565\n",
            "Epoch 5/10\n",
            "1238/1238 [==============================] - 33s 27ms/step - loss: 1.3022\n",
            "Epoch 6/10\n",
            "1238/1238 [==============================] - 33s 27ms/step - loss: 1.2550\n",
            "Epoch 7/10\n",
            "1238/1238 [==============================] - 33s 27ms/step - loss: 1.2164\n",
            "Epoch 8/10\n",
            "1238/1238 [==============================] - 33s 27ms/step - loss: 1.1857\n",
            "Epoch 9/10\n",
            "1238/1238 [==============================] - 34s 27ms/step - loss: 1.1632\n",
            "Epoch 10/10\n",
            "1238/1238 [==============================] - 34s 27ms/step - loss: 1.1480\n",
            "Joyce: Popery girls, pointing of her body\n",
            "across.\n",
            "\n",
            "Stephen played in all the friends from his even and,\n",
            "while Mr Holohans organs pride on the right steps and then, brought a match of\n",
            "shapely grandmothers Malliner hold of its rays without confused hands\n",
            "falls for nervous lyst top only but like that in his husband and\n",
            "he turned suddenly and that was present.\n",
            "\n",
            "His eye? lay a finely.\n",
            "\n",
            "O, dont make that two young men or the first rain honey, Miss\n",
            "OConnell Bridge said Mr Bartell DAccoll. He put his golden eyes for\n",
            "a rewly gardens and a carting officer. Nearly mentioned little womans to speak of\n",
            "the city again.\n",
            "\n",
            "Look at all, I can us, Mr Hill nothing for me, of course,\n",
            "the life of such priltiest! shillingsy: She would have been that thirty-men and mire!\n",
            "Here.\n",
            "\n",
            "Its on the gaunt      Aunt Julia, said Mary Jane, knew that his art\n",
            "wructly:\n",
            "\n",
            "Is that you were standing only to know?\n",
            "\n",
            "I am thought he was in Jeaus, Julia.\n",
            "\n",
            "John Gemmn? said Mr Cunningham. I all\n",
            "to tell her daunged Marth, I can scarch time.\n",
            "\n",
            "L \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.8513731956481934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model_loss(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "hnmI3oyFRvZa",
        "outputId": "a6585b59-d919-4d9a-baeb-98bb0bdb44fd"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing the input\n",
        "Let's feed a modern day storry teller writings as an input to our model.\n",
        "Obame - Obama Inaugural Address 2009."
      ],
      "metadata": {
        "id": "OsULda7w8sPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"modern_day/obama.txt\") as modern_file:\n",
        "  modern_text = modern_file.read()"
      ],
      "metadata": {
        "id": "LIWwZWv29f_Z"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model_exp1, chars_from_ids, ids_from_chars)\n",
        "generated = \"\"\n",
        "start_index = 0\n",
        "sentence = modern_text[start_index : start_index + maxlen*5]\n",
        "\n",
        "next_char = tf.constant([sentence])\n",
        "result = [next_char]\n",
        "start_index+=maxlen\n",
        "\n",
        "start = time.time()\n",
        "states = None\n",
        "\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'))\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uQvM4M8a3yE",
        "outputId": "7a343273-a63d-4072-d64b-efdc5187ac5a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My fellow citizens:\n",
            "\n",
            "I stand here today humbled by the task before us, grateful for the trust you have bestowed, mindful of the sacrifices borne by our ancestors. I thank President Bush for his service with\n",
            "his hit house and Mr Gretta Cowleys purpose to think that now then\n",
            "he slipped up her attitude and said:\n",
            "\n",
            "The carver of a low voice asked that Gabriel could he revalt it elucide\n",
            "in a letter. He had casted on. The pleasant harse had came\n",
            "actively grouplight with a dream of stylishings, a great was neither, without looking at the bat, and, at the sizgar of the\n",
            "little snap had failed to be wants made a cry. Aunt Kate framed the cut\n",
            "shed and she heard.\n",
            "\n",
            "A querultude of Dublin dont Mr Dedalus puffed down the poor abopt table and shaped\n",
            "his glass in her hands, saying: he had bring in a chair, her spords is\n",
            "coming to me, as we were all hungry from them but his arm actives to\n",
            "right sleek lightly amid behind the glass of milk but when he retreated from it to mission.\n",
            "There were suffered from their compliments. To impression and conscious of this\n",
            "nerves appeared violently everyone laughed ordinarious to any accordine note like\n",
            "that, and then that the corner of the past of the station excit\n",
            "\n",
            "Run time: 2.8516979217529297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model_exp1, chars_from_ids, ids_from_chars)\n",
        "start = time.time()\n",
        "states = None\n",
        "\n",
        "text_len = len(modern_text)\n",
        "words = modern_text.split()\n",
        "to_letters = [word for word in modern_text.split()[:250]]\n",
        "next_char = tf.constant(words)\n",
        "result = [words]\n",
        "\n",
        "# repeatedly feed our modelthe modern text\n",
        "for n_char in range(len(words)):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GVowGr3839O",
        "outputId": "c0997501-fa29-4c04-d53b-586d0337a875"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Myskimining his\n",
            "upper rail round the little cottons of gassive and oldigge:\n",
            "\n",
            "Quo Didnt seas on Mr Cunnng Maria!\n",
            "\n",
            "Considering herself with a blaub brother-in-law white tears: and the statue of the\n",
            "cowartyalthread-rooters were heads just as if he felt in the summer-face; and, when he\n",
            "was awakened into his boots. The man put himself he went\n",
            "over to the ladies of the presence of which Mr Alleyne was glass\n",
            "and still Early thereby coll-men of gust to such ruffian from weeks and words\n",
            "and the sandwise, repeated in natural issightance.\n",
            "\n",
            "The car drove every joke. But she can say it was there. Some country fellows, in\n",
            "Paradice Since whench the furnast mouth of the tamples well-window and\n",
            "happiert for he was very decend my head in audience. Not of her religion paralysnased\n",
            "by the sickcar away. She shome his mother had known a waught a line\n",
            "summance.\n",
            "\n",
            "O, look it, I pity something. Longest way a nice pain.\n",
            "\n",
            "Go worked rosiking in shrill and approvenge-on-the-boosery and said:\n",
            "\n",
            "Do you mean anything? O, \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 19.926172733306885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Even more text statistics"
      ],
      "metadata": {
        "id": "amcYk0z4pFAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_book_df():\n",
        "  book_list = [fold for file, der, fold in os.walk(\"book_project/\")][0]\n",
        "  books_df = pandas.DataFrame(columns=[\"book_name\", \"text\"])\n",
        "  for book in book_list:\n",
        "      with open(f\"book_project/{book}\", encoding=\"utf-8\") as book_file:\n",
        "          cleaned = clean_book(book_file)\n",
        "          books_df = books_df.append({\"book_name\": book, \"text\": cleaned}, ignore_index=True)\n",
        "  books_df[\"cleaned_description\"] = books_df.apply(lambda book_row: remove_non_ascii(book_row), axis=1)\n",
        "  return books_df\n",
        "\n",
        "\n",
        "books_df = create_book_df()\n",
        "\n",
        "all_words = \"\"\n",
        "for index, row in books_df.iterrows():\n",
        "    all_words += row[\"cleaned_description\"]\n",
        "\n",
        "vocab = sorted(set(all_words))\n",
        "print(f\"{len(vocab)} unique characters\")\n",
        "\n",
        "all_words_set = Counter(all_words.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myhlyCtspNVq",
        "outputId": "7ec64717-260e-4dcc-80c8-096866fcd0da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_longest_word(word_list):  \n",
        "    longest_word =  max(word_list, key=len)\n",
        "    return longest_word\n",
        "find_longest_word(all_words_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uEmsr8clqen9",
        "outputId": "588f3cfc-aaf1-457a-8f3e-c53e2d00eb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nationalgymnasiummuseumsanatoriumandsuspensoriumsordinaryprivatdocentge'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_length = dict()\n",
        "for word in all_words_set:\n",
        "  length = len(word)\n",
        "  if length in words_length:\n",
        "    words_length[length] += 1\n",
        "  else:\n",
        "    words_length[length] = 1\n",
        "words_length\n",
        "# lets remove the \"edges\"\n",
        "cleaned = dict()\n",
        "for key, value in words_length.items():\n",
        "  if value > 2:\n",
        "    cleaned[key]=value\n",
        "cleaned\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh7DtpJdq95E",
        "outputId": "7e1888f1-191c-40ab-dd8c-ac41e34da190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 56,\n",
              " 8: 8650,\n",
              " 2: 339,\n",
              " 3: 1381,\n",
              " 6: 8939,\n",
              " 5: 7131,\n",
              " 7: 9367,\n",
              " 14: 593,\n",
              " 4: 3978,\n",
              " 10: 5034,\n",
              " 9: 6869,\n",
              " 11: 3301,\n",
              " 19: 23,\n",
              " 13: 1108,\n",
              " 12: 1959,\n",
              " 16: 136,\n",
              " 15: 283,\n",
              " 17: 75,\n",
              " 18: 31,\n",
              " 20: 12,\n",
              " 21: 6,\n",
              " 24: 4,\n",
              " 22: 4,\n",
              " 27: 3,\n",
              " 34: 3}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar(*zip(*cleaned.items()))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zNFlem9itknC",
        "outputId": "7d1c4fb8-1793-4ea4-bfcf-a091c766a218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rJz-F6aIs18C",
        "2BnMma8iyRey",
        "4CWnd73WteQA",
        "HF8ay3RTy7KP",
        "vjnI8OJLvgBI",
        "5wrP5am3Hk9_",
        "Nhz5-GJ6IM33",
        "WddHjfUAne9Y",
        "amcYk0z4pFAC"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}